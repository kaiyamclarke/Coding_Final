{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import math\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from numpy import genfromtxt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"life_expectancy_X.csv\").to_numpy()\n",
    "Y = pd.read_csv(\"life_expectancy_y.csv\").to_numpy()\n",
    "n = len(Y)\n",
    "Y = np.reshape(Y,(n,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Bias to X\n",
    "X = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "# Scale the data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use HSIC between each feature and label to identify the features that have the strongest dependency on the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSIC(X, Y):\n",
    "    γ = 1 \n",
    "    K_x = rbf_kernel(X, gamma=1)\n",
    "    K_y = rbf_kernel(X, gamma=1)\n",
    "    C = np.eye(n) - ((1/n) * np.ones((n,n)))\n",
    "    return np.trace(K_x.dot(C).dot(K_y).dot(C))/ (n*n)\n",
    "\n",
    "features = np.array([['Exercise amount'], \n",
    "            ['supportive relationships'] ,\n",
    "            ['Num siblings'], \n",
    "            ['Alcohol / Drugs consumption'], \n",
    "            ['Height'], ['Attractiveness'] ,['work ethic'], ['bias']])\n",
    "\n",
    "HSIC_list = []\n",
    "for f in X.T:\n",
    "    f = np.reshape(f, (n,1))\n",
    "    HSIC_list.append(HSIC(f, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exercise amount</th>\n",
       "      <th>supportive relationships</th>\n",
       "      <th>Num siblings</th>\n",
       "      <th>Alcohol / Drugs consumption</th>\n",
       "      <th>Height</th>\n",
       "      <th>Attractiveness</th>\n",
       "      <th>work ethic</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015822</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.026307</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>7.476939e-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Exercise amount  supportive relationships  Num siblings  \\\n",
       "0         0.015822                  0.017959      0.026307   \n",
       "\n",
       "   Alcohol / Drugs consumption    Height  Attractiveness  work ethic  \\\n",
       "0                     0.016401  0.016604        0.016032    0.015122   \n",
       "\n",
       "           bias  \n",
       "0  7.476939e-31  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert features to a list\n",
    "features_list = features.flatten().tolist()\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data=[HSIC_list], columns=features_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ISM to identify the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ = 1\n",
    "X = genfromtxt(\"life_expectancy_X.csv\", delimiter=',')\n",
    "y = genfromtxt(\"life_expectancy_y.csv\")\n",
    "Y = np.reshape(y, (len(y), 1))\n",
    "# Scale the data between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Y_0 = OneHotEncoder(categories='auto', sparse=False).fit_transform(Y)\n",
    "K_r = Y_0.dot(np.transpose(Y_0))\n",
    "R = np.transpose((np.transpose(K_r - np.mean(K_r, axis=0))) - np.mean(np.transpose((K_r - np.mean(K_r, axis=0))), axis=0))\n",
    "D = np.diag(np.sum(R, axis=0))\n",
    "L = D - R\n",
    "Φ = -X.T.dot(L).dot(X) \n",
    "eigen_val, W_1 = eig(Φ)\n",
    "W_1 = W_1[:, ::-1][:, 0:Φ.shape[0]]\n",
    "eigen_val = np.flip(eigen_val)[0:Φ.shape[0]]\n",
    "Σ = np.diag(eigen_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen_val_0 = np.array([1,1,1,1,1,1,1])\n",
    "while True:\n",
    "    K_x = rbf_kernel(X.dot(W_1), gamma = γ)\n",
    "    Ψ =  R * K_x\n",
    "    D = np.diag(np.sum(Ψ,axis=0))\n",
    "    L = D - Ψ \n",
    "    Φ = -X.T.dot(L).dot(X)\n",
    "    eigen_val, W_1 = eig(Φ)\n",
    "    W_1 = W_1[:, ::-1][:, 0:Φ.shape[0]]\n",
    "    eigen_val = np.flip(eigen_val)[0:Φ.shape[0]]\n",
    "    Σ = np.diag(eigen_val)\n",
    "    if norm(eigen_val_0 - eigen_val) < 0.01: break\n",
    "    eigen_val_0 = eigen_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = np.array([['Exercise amount'], \n",
    "            ['Amount of supportive relationships'] ,\n",
    "            ['Number of siblings'], \n",
    "            ['Alcohol / Drugs / Smoking consumption'], \n",
    "            ['Height'], ['Attractiveness'] ,['work ethic']])\n",
    "\n",
    "eigen_val, W_1 = eig(Φ)\n",
    "W_1 = W_1[:, ::-1][:, 0:Φ.shape[0]]\n",
    "eigen_val = np.flip(eigen_val)[0:Φ.shape[0]]\n",
    "index_of_largest_eigen = np.argmax(eigen_val)\n",
    "W_1 = W_1[index_of_largest_eigen]\n",
    "W_1 = np.round(W_1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert name and W_1 to DataFrame\n",
    "df = pd.DataFrame(data=W_1, columns=['Weights'], index=name.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Weights\n",
      "Exercise amount                          0.415\n",
      "Amount of supportive relationships       0.262\n",
      "Number of siblings                       0.486\n",
      "Alcohol / Drugs / Smoking consumption   -0.315\n",
      "Height                                   0.631\n",
      "Attractiveness                          -0.081\n",
      "work ethic                              -0.133\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between the results from ISM and measuring via HSIC feature by feature?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ISM, the Alcohol and Drug Consumption, Attractiveness and work ethic seem to negatively impact life expectancy with Alcohol and Drug consumption being the largest negative weight having the greatest negative impact. Height is the highest weighted positive amount in ISM. While in HSIC supportive relationships and Alcohol and Drug consumption seem to be the highest impacted features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
